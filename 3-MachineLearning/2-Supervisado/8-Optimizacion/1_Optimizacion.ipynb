{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6869d9",
   "metadata": {},
   "source": [
    "# Optimización de Hiperparámetros en Machine Learning\n",
    "\n",
    "Este notebook explora diferentes técnicas de optimización de hiperparámetros usando el dataset del Titanic:\n",
    "1. GridSearchCV\n",
    "2. RandomizedSearchCV\n",
    "3. Optimización Bayesiana (con scikit-optimize)\n",
    "4. Optuna\n",
    "\n",
    "## Preparación de datos y configuración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75b82abf",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Importamos las bibliotecas necesarias\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16604094",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Cargamos y preparamos los datos del Titanic\n",
    "def preparar_datos_titanic():\n",
    "    # Cargamos los datos\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv')\n",
    "\n",
    "    # Preprocesamiento básico\n",
    "    df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "    df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "    # Codificación de variables categóricas\n",
    "    df['Sex'] = df['Sex'].map({'female': 1, 'male': 0})\n",
    "    embarked_dummies = pd.get_dummies(df['Embarked'], prefix='Embarked')\n",
    "    df = pd.concat([df, embarked_dummies], axis=1)\n",
    "\n",
    "    # Seleccionamos características\n",
    "    features = ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
    "               'Embarked_C', 'Embarked_Q', 'Embarked_S']\n",
    "    X = df[features]\n",
    "    y = df['Survived']\n",
    "\n",
    "    # Dividimos los datos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Escalamos las características\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b960bb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos\n",
    "X_train, X_test, y_train, y_test = preparar_datos_titanic()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d856de",
   "metadata": {},
   "source": [
    "## 1. GridSearchCV\n",
    "Búsqueda exhaustiva en una cuadrícula de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a01957b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Grid): {'max_depth': 10, 'min_samples_leaf': 4, 'min_samples_split': 10, 'n_estimators': 100}\n",
      "Mejor puntuación (Grid): 0.8314192849404117\n",
      "\n",
      "Informe de clasificación (Grid):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.86       105\n",
      "           1       0.84      0.72      0.77        74\n",
      "\n",
      "    accuracy                           0.83       179\n",
      "   macro avg       0.83      0.81      0.82       179\n",
      "weighted avg       0.83      0.83      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Definimos el espacio de búsqueda\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [10, 20, 30, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Creamos y ejecutamos GridSearchCV\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos los resultados\n",
    "print(\"Mejores parámetros (Grid):\", grid_search.best_params_)\n",
    "print(\"Mejor puntuación (Grid):\", grid_search.best_score_)\n",
    "y_pred_grid = grid_search.predict(X_test)\n",
    "print(\"\\nInforme de clasificación (Grid):\")\n",
    "print(classification_report(y_test, y_pred_grid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a689ab",
   "metadata": {},
   "source": [
    "Al tener: Mejor puntuación (Grid): 0.8314192849404117 y  accuracy = 0.83 eso es bueno , misma puntuacion, lo malo es que la acurasi sea peor que la puntuacion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3aec54c",
   "metadata": {},
   "source": [
    "## 2. RandomizedSearchCV\n",
    "Búsqueda aleatoria en el espacio de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6512a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Random): {'max_depth': 28, 'min_samples_leaf': 7, 'min_samples_split': 12, 'n_estimators': 187}\n",
      "Mejor puntuación (Random): 0.8286319314488327\n",
      "\n",
      "Informe de clasificación (Random):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.86       105\n",
      "           1       0.84      0.70      0.76        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.83      0.80      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "\n",
    "# Definimos distribuciones para los parámetros\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(10, 50),\n",
    "    'min_samples_split': randint(2, 15),\n",
    "    'min_samples_leaf': randint(1, 10)\n",
    "}\n",
    "\n",
    "# Creamos y ejecutamos RandomizedSearchCV\n",
    "random_search = RandomizedSearchCV(\n",
    "    rf, param_distributions, n_iter=20, cv=5,   #  n_iter=20 cojeme solo 20 combinaciones aleatorias, NO me agas todas las combinaciones podibles\n",
    "    scoring='accuracy', n_jobs=-1, random_state=42\n",
    ")\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos los resultados\n",
    "print(\"Mejores parámetros (Random):\", random_search.best_params_)\n",
    "print(\"Mejor puntuación (Random):\", random_search.best_score_)\n",
    "y_pred_random = random_search.predict(X_test)\n",
    "print(\"\\nInforme de clasificación (Random):\")\n",
    "print(classification_report(y_test, y_pred_random))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f266c22",
   "metadata": {},
   "source": [
    "## 3. Optimización Bayesiana\n",
    "Usando scikit-optimize para búsqueda más eficiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43b936f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Bayes): OrderedDict([('max_depth', 41), ('min_samples_leaf', 6), ('min_samples_split', 5), ('n_estimators', 500)])\n",
      "Mejor puntuación (Bayes): 0.8272037821333595\n",
      "\n",
      "Informe de clasificación (Bayes):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.86       105\n",
      "           1       0.84      0.70      0.76        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.83      0.80      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Integer, Real\n",
    "\n",
    "# Definimos el espacio de búsqueda\n",
    "bayes_space = {\n",
    "    'n_estimators': Integer(100, 500),\n",
    "    'max_depth': Integer(10, 50),\n",
    "    'min_samples_split': Integer(2, 15),\n",
    "    'min_samples_leaf': Integer(1, 10)\n",
    "}\n",
    "\n",
    "# Creamos y ejecutamos BayesSearchCV\n",
    "bayes_search = BayesSearchCV(\n",
    "    rf, bayes_space, n_iter=20, cv=5,\n",
    "    scoring='accuracy', n_jobs=-1, random_state=42\n",
    ")\n",
    "bayes_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluamos los resultados\n",
    "print(\"Mejores parámetros (Bayes):\", bayes_search.best_params_)\n",
    "print(\"Mejor puntuación (Bayes):\", bayes_search.best_score_)\n",
    "y_pred_bayes = bayes_search.predict(X_test)\n",
    "print(\"\\nInforme de clasificación (Bayes):\")\n",
    "print(classification_report(y_test, y_pred_bayes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da5768",
   "metadata": {},
   "source": [
    "## 4. Optuna\n",
    "Framework de optimización automática de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fc9394a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-08 13:35:16,247] A new study created in memory with name: no-name-bc9ec37e-132a-466f-83b9-c590822b0f41\n",
      "[I 2025-02-08 13:35:16,833] Trial 0 finished with value: 0.821609376538954 and parameters: {'n_estimators': 123, 'max_depth': 43, 'min_samples_split': 15, 'min_samples_leaf': 6}. Best is trial 0 with value: 0.821609376538954.\n",
      "[I 2025-02-08 13:35:18,476] Trial 1 finished with value: 0.8173840244262781 and parameters: {'n_estimators': 430, 'max_depth': 47, 'min_samples_split': 2, 'min_samples_leaf': 8}. Best is trial 0 with value: 0.821609376538954.\n",
      "[I 2025-02-08 13:35:20,124] Trial 2 finished with value: 0.821589677927706 and parameters: {'n_estimators': 447, 'max_depth': 39, 'min_samples_split': 8, 'min_samples_leaf': 4}. Best is trial 0 with value: 0.821609376538954.\n",
      "[I 2025-02-08 13:35:20,757] Trial 3 finished with value: 0.8272136314389836 and parameters: {'n_estimators': 195, 'max_depth': 31, 'min_samples_split': 13, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8272136314389836.\n",
      "[I 2025-02-08 13:35:21,773] Trial 4 finished with value: 0.8201812272234807 and parameters: {'n_estimators': 273, 'max_depth': 14, 'min_samples_split': 12, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8272136314389836.\n",
      "[I 2025-02-08 13:35:23,376] Trial 5 finished with value: 0.8145966709346991 and parameters: {'n_estimators': 328, 'max_depth': 18, 'min_samples_split': 6, 'min_samples_leaf': 1}. Best is trial 3 with value: 0.8272136314389836.\n",
      "[I 2025-02-08 13:35:25,590] Trial 6 finished with value: 0.8202009258347287 and parameters: {'n_estimators': 322, 'max_depth': 44, 'min_samples_split': 9, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8272136314389836.\n",
      "[I 2025-02-08 13:35:27,176] Trial 7 finished with value: 0.8230079779375554 and parameters: {'n_estimators': 224, 'max_depth': 23, 'min_samples_split': 8, 'min_samples_leaf': 8}. Best is trial 3 with value: 0.8272136314389836.\n",
      "[I 2025-02-08 13:35:28,932] Trial 8 finished with value: 0.821619225844578 and parameters: {'n_estimators': 339, 'max_depth': 11, 'min_samples_split': 4, 'min_samples_leaf': 2}. Best is trial 3 with value: 0.8272136314389836.\n",
      "[I 2025-02-08 13:35:30,255] Trial 9 finished with value: 0.8229882793263075 and parameters: {'n_estimators': 224, 'max_depth': 38, 'min_samples_split': 14, 'min_samples_leaf': 9}. Best is trial 3 with value: 0.8272136314389836.\n",
      "[I 2025-02-08 13:35:30,782] Trial 10 finished with value: 0.8272037821333595 and parameters: {'n_estimators': 110, 'max_depth': 30, 'min_samples_split': 12, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8272136314389836.\n",
      "[I 2025-02-08 13:35:31,509] Trial 11 finished with value: 0.8257854821235103 and parameters: {'n_estimators': 130, 'max_depth': 30, 'min_samples_split': 12, 'min_samples_leaf': 5}. Best is trial 3 with value: 0.8272136314389836.\n",
      "[I 2025-02-08 13:35:32,488] Trial 12 finished with value: 0.8258150300403821 and parameters: {'n_estimators': 169, 'max_depth': 28, 'min_samples_split': 12, 'min_samples_leaf': 6}. Best is trial 3 with value: 0.8272136314389836.\n",
      "[I 2025-02-08 13:35:33,402] Trial 13 finished with value: 0.8229882793263075 and parameters: {'n_estimators': 188, 'max_depth': 35, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 3 with value: 0.8272136314389836.\n",
      "[I 2025-02-08 13:35:33,875] Trial 14 finished with value: 0.8328474342558849 and parameters: {'n_estimators': 100, 'max_depth': 25, 'min_samples_split': 13, 'min_samples_leaf': 5}. Best is trial 14 with value: 0.8328474342558849.\n",
      "[I 2025-02-08 13:35:34,816] Trial 15 finished with value: 0.8201910765291046 and parameters: {'n_estimators': 164, 'max_depth': 23, 'min_samples_split': 14, 'min_samples_leaf': 10}. Best is trial 14 with value: 0.8328474342558849.\n",
      "[I 2025-02-08 13:35:36,249] Trial 16 finished with value: 0.8229882793263075 and parameters: {'n_estimators': 257, 'max_depth': 24, 'min_samples_split': 10, 'min_samples_leaf': 4}. Best is trial 14 with value: 0.8328474342558849.\n",
      "[I 2025-02-08 13:35:36,751] Trial 17 finished with value: 0.8187826258248794 and parameters: {'n_estimators': 102, 'max_depth': 34, 'min_samples_split': 15, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.8328474342558849.\n",
      "[I 2025-02-08 13:35:39,038] Trial 18 finished with value: 0.8201910765291048 and parameters: {'n_estimators': 382, 'max_depth': 26, 'min_samples_split': 13, 'min_samples_leaf': 7}. Best is trial 14 with value: 0.8328474342558849.\n",
      "[I 2025-02-08 13:35:40,244] Trial 19 finished with value: 0.8173544765094061 and parameters: {'n_estimators': 210, 'max_depth': 19, 'min_samples_split': 10, 'min_samples_leaf': 3}. Best is trial 14 with value: 0.8328474342558849.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores parámetros (Optuna): {'n_estimators': 100, 'max_depth': 25, 'min_samples_split': 13, 'min_samples_leaf': 5}\n",
      "Mejor puntuación (Optuna): 0.8328474342558849\n",
      "\n",
      "Informe de clasificación (Optuna):\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.85       105\n",
      "           1       0.82      0.69      0.75        74\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.79      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "\n",
    "def objetivo(trial):\n",
    "    # Definimos el espacio de búsqueda\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 10, 50),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 15),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    }\n",
    "\n",
    "    # Creamos y entrenamos el modelo\n",
    "    rf = RandomForestClassifier(**params, random_state=42)\n",
    "\n",
    "    # Evaluamos usando validación cruzada\n",
    "    scores = cross_val_score(rf, X_train, y_train, cv=5, scoring='accuracy')\n",
    "    return scores.mean()\n",
    "\n",
    "# Creamos y ejecutamos el estudio de Optuna\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objetivo, n_trials=20)\n",
    "\n",
    "# Evaluamos los resultados\n",
    "print(\"Mejores parámetros (Optuna):\", study.best_params)\n",
    "print(\"Mejor puntuación (Optuna):\", study.best_value)\n",
    "\n",
    "# Entrenamos el modelo final con los mejores parámetros\n",
    "rf_final = RandomForestClassifier(**study.best_params, random_state=42)\n",
    "rf_final.fit(X_train, y_train)\n",
    "y_pred_optuna = rf_final.predict(X_test)\n",
    "print(\"\\nInforme de clasificación (Optuna):\")\n",
    "print(classification_report(y_test, y_pred_optuna))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ba44be",
   "metadata": {},
   "source": [
    "## Comparación de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a21d102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparación de resultados:\n",
      "               Método  Accuracy\n",
      "0        GridSearchCV  0.826816\n",
      "1  RandomizedSearchCV  0.821229\n",
      "2       BayesSearchCV  0.821229\n",
      "3              Optuna  0.810056\n"
     ]
    }
   ],
   "source": [
    "# Creamos un DataFrame con los resultados\n",
    "resultados = pd.DataFrame({\n",
    "    'Método': ['GridSearchCV', 'RandomizedSearchCV', 'BayesSearchCV', 'Optuna'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_test, y_pred_grid),\n",
    "        accuracy_score(y_test, y_pred_random),\n",
    "        accuracy_score(y_test, y_pred_bayes),\n",
    "        accuracy_score(y_test, y_pred_optuna)\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"Comparación de resultados:\")\n",
    "print(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe87d74",
   "metadata": {},
   "source": [
    "## Conclusiones\n",
    "\n",
    "Este notebook demuestra diferentes métodos de optimización de hiperparámetros:\n",
    "\n",
    "1. GridSearchCV: Búsqueda exhaustiva pero computacionalmente costosa\n",
    "2. RandomizedSearchCV: Más eficiente que Grid Search, buenos resultados con menos tiempo\n",
    "3. Optimización Bayesiana: Búsqueda inteligente que aprende de iteraciones anteriores\n",
    "4. Optuna: Framework moderno con características avanzadas y visualización\n",
    "\n",
    "Cada método tiene sus ventajas y desventajas en términos de tiempo de computación y calidad de resultados."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
